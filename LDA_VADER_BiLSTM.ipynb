{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4156437,"sourceType":"datasetVersion","datasetId":2421846}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n\n# Load the dataset (assuming it's in 'monkeypox_tweets.csv')\ndf = pd.read_csv('/kaggle/working/merged.csv')\n\n# Filter for English language tweets if needed\ndf = df[df['language'] == 'en']\n\n# Initialize VADER sentiment analyzer\nanalyzer = SentimentIntensityAnalyzer()\n\n# Apply VADER to get sentiment scores for each tweet\ndf['vader_sentiment'] = df['tweet'].apply(lambda tweet: analyzer.polarity_scores(tweet)['compound'])\n\n# Convert sentiment scores to categorical labels\ndf['vader_sentiment_label'] = df['vader_sentiment'].apply(lambda score: 'positive' if score >= 0.05 else ('negative' if score <= -0.05 else 'neutral'))\n\n# Display sentiment results\nprint(df[['tweet', 'vader_sentiment', 'vader_sentiment_label']])\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-15T03:51:12.190203Z","iopub.execute_input":"2024-10-15T03:51:12.190605Z","iopub.status.idle":"2024-10-15T03:51:26.489004Z","shell.execute_reply.started":"2024-10-15T03:51:12.190567Z","shell.execute_reply":"2024-10-15T03:51:26.487986Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3828540240.py:5: DtypeWarning: Columns (0,1,2,4,5,10,13,14,15,16,17,18,19,20,21,22,23,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/kaggle/working/merged.csv')\n","output_type":"stream"},{"name":"stdout","text":"                                                    tweet  vader_sentiment  \\\n0       @larryd5674 @John_Kass @chicagosmayor @SAKimFo...           0.4404   \n1       Monkeypox: An explainer and research roundup  ...           0.0000   \n2       About Monkeypox and HOCl makers….I’m learning ...           0.4019   \n4       Many like to see the U.S. as one of the most a...          -0.0018   \n5       🚨🚨LA County sex workers: Monkey pox vaccines a...           0.0000   \n...                                                   ...              ...   \n171098  Lying that I have monkeypox so people beleive ...          -0.5267   \n171099  KingBee Interview, Monkeypox , This Or That, &...           0.2500   \n171100  @JLeiper @OttawaHealth That’s the place for mo...           0.0000   \n171101  (SACRAMENTO)A UC Davis Health study finds that...           0.7184   \n171102  “I’ve not heard of one action directly aimed a...           0.2960   \n\n       vader_sentiment_label  \n0                   positive  \n1                    neutral  \n2                   positive  \n4                    neutral  \n5                    neutral  \n...                      ...  \n171098              negative  \n171099              positive  \n171100               neutral  \n171101              positive  \n171102              positive  \n\n[82822 rows x 3 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each sentiment category\nsentiment_counts = df['vader_sentiment_label'].value_counts().to_frame()\n\n# Convert index into a column for easy plotting\nsentiment_counts.reset_index(inplace=True)\nsentiment_counts.columns = ['Sentiment', 'Count']\n\n# Plot heatmap (but this will be more like a heatmap-style barplot)\nplt.figure(figsize=(6, 4))\nsns.heatmap(sentiment_counts[['Count']].T, annot=sentiment_counts[['Count']].T, cmap='Blues', cbar=False, fmt='d')\nplt.yticks([0.5], ['Sentiment Counts'], rotation=0)\nplt.xticks(ticks=[i+0.5 for i in range(len(sentiment_counts))], labels=sentiment_counts['Sentiment'])\n\nplt.title('Heatmap of Sentiment Counts')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:36:57.914782Z","iopub.execute_input":"2024-10-15T03:36:57.915675Z","iopub.status.idle":"2024-10-15T03:36:58.160476Z","shell.execute_reply.started":"2024-10-15T03:36:57.915635Z","shell.execute_reply":"2024-10-15T03:36:58.159386Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"!pip install vaderSentiment","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:30:45.335435Z","iopub.execute_input":"2024-10-15T03:30:45.335786Z","iopub.status.idle":"2024-10-15T03:30:58.140785Z","shell.execute_reply.started":"2024-10-15T03:30:45.335750Z","shell.execute_reply":"2024-10-15T03:30:58.139697Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting vaderSentiment\n  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.8.30)\nDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: vaderSentiment\nSuccessfully installed vaderSentiment-3.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\nfrom tensorflow.keras.models import Sequential\n\n# Tokenize and preprocess the tweets\nmax_features = 10000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(df['tweet'])\nsequences = tokenizer.texts_to_sequences(df['tweet'])\npadded_sequences = pad_sequences(sequences, maxlen=100)\n\n# Assuming sentiment labels are created (you can use VADER results)\ndf['sentiment_label'] = df['vader_sentiment_label'].apply(lambda x: 1 if x == 'positive' else (0 if x == 'neutral' else -1))\n\n# Split data into train and test\nX_train, X_test, y_train, y_test = train_test_split(padded_sequences, df['sentiment_label'], test_size=0.2)\n\n# Define BiLSTM model\nmodel = Sequential()\nmodel.add(Embedding(max_features, 128))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile and train the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:37:50.562120Z","iopub.execute_input":"2024-10-15T03:37:50.563000Z","iopub.status.idle":"2024-10-15T03:40:34.822049Z","shell.execute_reply.started":"2024-10-15T03:37:50.562948Z","shell.execute_reply":"2024-10-15T03:40:34.821072Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m2071/2071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 13ms/step - accuracy: 0.4182 - loss: -4.4287 - val_accuracy: 0.4370 - val_loss: -22.2311\nEpoch 2/5\n\u001b[1m2071/2071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.4578 - loss: -34.3877 - val_accuracy: 0.4358 - val_loss: -54.3870\nEpoch 3/5\n\u001b[1m2071/2071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.4838 - loss: -69.0203 - val_accuracy: 0.4941 - val_loss: -99.9786\nEpoch 4/5\n\u001b[1m2071/2071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.4960 - loss: -123.8218 - val_accuracy: 0.4882 - val_loss: -150.1174\nEpoch 5/5\n\u001b[1m2071/2071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.5278 - loss: -179.1410 - val_accuracy: 0.5066 - val_loss: -201.4306\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5049 - loss: -198.0529\nTest Accuracy: 0.5066103339195251\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport gensim\nfrom gensim import corpora\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# Ensure you have the required NLTK stopwords package\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# Load your dataset (assuming it's already merged)\ndf = pd.read_csv('/kaggle/working/merged.csv')\n\n# Filter only English tweets if needed\ndf = df[df['language'] == 'en']\n\n# Preprocessing function to clean and tokenize tweets\nstop_words = set(stopwords.words('english'))\ndef preprocess(text):\n    # Tokenize and remove stop words\n    tokens = word_tokenize(text.lower())\n    return [word for word in tokens if word.isalpha() and word not in stop_words]\n\n# Apply preprocessing to the tweet column\ndf['processed_tweet'] = df['tweet'].apply(preprocess)\n\n# Create dictionary and corpus for LDA\ndictionary = corpora.Dictionary(df['processed_tweet'])\ncorpus = [dictionary.doc2bow(text) for text in df['processed_tweet']]\n\n# Apply LDA model\nlda_model = gensim.models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n\n# Print the topics found by LDA\ntopics = lda_model.print_topics(num_words=5)\nfor topic in topics:\n    print(topic)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:42:21.178129Z","iopub.execute_input":"2024-10-15T03:42:21.178906Z","iopub.status.idle":"2024-10-15T03:46:15.420134Z","shell.execute_reply.started":"2024-10-15T03:42:21.178865Z","shell.execute_reply":"2024-10-15T03:46:15.419087Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2315852135.py:13: DtypeWarning: Columns (0,1,2,4,5,10,13,14,15,16,17,18,19,20,21,22,23,25,32) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv('/kaggle/working/merged.csv')\n","output_type":"stream"},{"name":"stdout","text":"(0, '0.131*\"monkey\" + 0.129*\"pox\" + 0.036*\"monkeypox\" + 0.021*\"got\" + 0.014*\"jackposobiec\"')\n(1, '0.115*\"https\" + 0.100*\"monkeypox\" + 0.020*\"cases\" + 0.020*\"vaccine\" + 0.018*\"health\"')\n(2, '0.066*\"monkeypox\" + 0.014*\"people\" + 0.011*\"get\" + 0.011*\"covid\" + 0.010*\"gay\"')\n(3, '0.024*\"monkeypox\" + 0.014*\"school\" + 0.013*\"amp\" + 0.009*\"covid\" + 0.006*\"ever\"')\n(4, '0.069*\"monkeypox\" + 0.049*\"https\" + 0.032*\"hiv\" + 0.027*\"man\" + 0.026*\"first\"')\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:48:50.768366Z","iopub.execute_input":"2024-10-15T03:48:50.769148Z","iopub.status.idle":"2024-10-15T03:49:02.336287Z","shell.execute_reply.started":"2024-10-15T03:48:50.769105Z","shell.execute_reply":"2024-10-15T03:49:02.335132Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\n\n# Load the merged dataset\n# Filter for English tweets\ndf = df[df['language'] == 'en']\n\n# Assuming you have labeled the data with 'positive', 'neutral', 'negative' (if not, VADER results can be used for labels)\n# If you have no labels, you can use VADER sentiment or similar to generate labels first\n# Example: df['true_sentiment'] could be ['positive', 'neutral', 'negative']\n# You can replace this with your sentiment labels\n\n# Encoding the labels\nlabel_encoder = LabelEncoder()\ndf2 = df\ndf2['label'] = label_encoder.fit_transform(df['vader_sentiment_label'])\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2, random_state=42)\n\n# Load pre-trained BERT tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n\n# Tokenize the input tweets\ndef encode_tweets(tweets):\n    return tokenizer(\n        tweets.tolist(), \n        padding=True, \n        truncation=True, \n        max_length=128, \n        return_tensors='tf'\n    )\n\nX_train_encoded = encode_tweets(X_train)\nX_test_encoded = encode_tweets(X_test)\n\n# Convert labels to tensors\ny_train_encoded = tf.convert_to_tensor(y_train.values)\ny_test_encoded = tf.convert_to_tensor(y_test.values)\n\n# Use TensorFlow's optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n\n# Compile the model\nmodel.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n\n# Train the model\nmodel.fit(\n    X_train_encoded['input_ids'], \n    y_train_encoded, \n    epochs=3, \n    batch_size=16, \n    validation_data=(X_test_encoded['input_ids'], y_test_encoded)\n)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test_encoded['input_ids'], y_test_encoded)\nprint(f\"Test Accuracy: {accuracy}\")\n\n# Make predictions\npredictions = model.predict(X_test_encoded['input_ids']).logits\npredictions_labels = tf.argmax(predictions, axis=1)\n\n# Convert numeric predictions back to sentiment labels\npredicted_labels = label_encoder.inverse_transform(predictions_labels.numpy())\n\n# Generate a classification report\nprint(classification_report(y_test, predicted_labels, target_names=label_encoder.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-10-15T03:56:38.127658Z","iopub.execute_input":"2024-10-15T03:56:38.128216Z","iopub.status.idle":"2024-10-15T03:58:04.056657Z","shell.execute_reply.started":"2024-10-15T03:56:38.128172Z","shell.execute_reply":"2024-10-15T03:58:04.055207Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     56\u001b[0m     X_train_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     57\u001b[0m     y_train_encoded, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], y_test_encoded)\n\u001b[1;32m     61\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1563\u001b[0m, in \u001b[0;36mTFPreTrainedModel.compile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# This argument got renamed, we need to support both versions\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parent_args:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweighted_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1575\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m   1576\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1583\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/optimizers/__init__.py:335\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get(\n\u001b[1;32m    331\u001b[0m         config,\n\u001b[1;32m    332\u001b[0m         use_legacy_optimizer\u001b[38;5;241m=\u001b[39muse_legacy_optimizer,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     )\n","\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7c231b4b84c0>"],"ename":"ValueError","evalue":"Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7c231b4b84c0>","output_type":"error"}]}]}